import feedparser
import google.generativeai as genai
import os
import json

RSS_URL = "[https://news.google.com/rss/search?q=AI+Artificial+Intelligence+when:1d&hl=ja&gl=JP&ceid=JP:ja](https://news.google.com/rss/search?q=AI+Artificial+Intelligence+when:1d&hl=ja&gl=JP&ceid=JP:ja)"
MAX_ARTICLES = 5

def generate_news():
    api_key = os.environ.get("GEMINI_API_KEY")
    if not api_key:
        return {"column": "APIã‚­ãƒ¼ã‚¨ãƒ©ãƒ¼", "articles": []}

    # AIè¨­å®š
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel(
        'gemini-1.5-flash',
        generation_config={"response_mime_type": "application/json"}
    )

    print("ğŸ“° Googleãƒ‹ãƒ¥ãƒ¼ã‚¹ã‹ã‚‰è¨˜äº‹ã‚’å–å¾—ä¸­...")
    feed = feedparser.parse(RSS_URL)
    
    if not feed.entries:
        return {"column": "è¨˜äº‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚", "articles": []}

    # å¤‰æ•°åã‚’ 'articles' ã«çµ±ä¸€
    articles = feed.entries[:MAX_ARTICLES]
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
    prompt = "ä»¥ä¸‹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ãƒªã‚¹ãƒˆã‚’èª­ã¿ã€Webã‚µã‚¤ãƒˆæ²è¼‰ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’JSONå½¢å¼ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚\n"
    prompt += "ã€è¦ä»¶ã€‘\n"
    prompt += "1. `items`: å„è¨˜äº‹ã«ã¤ã„ã¦ã€catch_copy(30æ–‡å­—ä»¥å†…ã®è¦‹å‡ºã—)ã€ã¨ã€summary(100æ–‡å­—ç¨‹åº¦ã®è¦ç´„)ã€ã‚’ä½œæˆã€‚\n"
    prompt += "2. `column`: è¨˜äº‹å…¨ä½“ã‹ã‚‰èª­ã¿å–ã‚Œã‚‹ã€ä»Šæ—¥ã®AIæ¥­ç•Œã®å‹•ãã€ã‚’300æ–‡å­—ç¨‹åº¦ã®ã‚³ãƒ©ãƒ ã¨ã—ã¦ä½œæˆã€‚\n\n"
    prompt += "ã€è¨˜äº‹ãƒªã‚¹ãƒˆã€‘\n"
    
    for i, entry in enumerate(articles):
        prompt += f"ID:{i} ã‚¿ã‚¤ãƒˆãƒ«:{entry.title}\n"

    try:
        # AIã«ç”Ÿæˆã•ã›ã‚‹
        response = model.generate_content(prompt)
        text = response.text

        # ã‚¨ãƒ©ãƒ¼å›é¿ï¼šMarkdownè¨˜æ³•ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã«å–ã‚Šé™¤ãå‡¦ç†
        if "```json" in text:
            text = text.replace("```json", "").replace("```", "")
        elif "```" in text:
            text = text.replace("```", "")
        
        # JSONãƒ†ã‚­ã‚¹ãƒˆã‚’Pythonã®è¾æ›¸ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
        ai_data = json.loads(text)
        
        # çµæœã‚’çµåˆ
        final_articles = []
        ai_items = ai_data.get("items", [])
        
        for i, entry in enumerate(articles):
            # AIã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã‹ç¢ºèªã—ã¦çµåˆ
            ai_item = ai_items[i] if i < len(ai_items) else {"catch_copy": entry.title, "summary": "è¦ç´„ç”Ÿæˆå¤±æ•—"}
            
            final_articles.append({
                "title": entry.title,
                "url": entry.link,
                "date": entry.published if 'published' in entry else "",
                "headline": ai_item.get("catch_copy", entry.title),
                "summary": ai_item.get("summary", "")
            })

        return {
            "column": ai_data.get("column", "ã‚³ãƒ©ãƒ ç”Ÿæˆå¤±æ•—"),
            "articles": final_articles
        }

    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚æœ€ä½é™ã®æƒ…å ±ã‚’è¿”ã™
        return {"column": f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", "articles": []}

if __name__ == "__main__":
    result = generate_news()
    print(f"ã‚³ãƒ©ãƒ : {result['column'][:50]}...")
    print(f"è¨˜äº‹æ•°: {len(result['articles'])}")
